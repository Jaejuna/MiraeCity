{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rootdir = 'C:/Users/user/git/MiraeCity/gesture/labels/txt/'\n",
    "\n",
    "# Get all txt files in root directory\n",
    "txt_files = glob.glob(os.path.join(rootdir, '*.txt'))\n",
    "\n",
    "for txt_file in txt_files:\n",
    "    # Read txt file\n",
    "    with open(txt_file, 'r') as f:\n",
    "        data = f.readlines()\n",
    "    \n",
    "    # Split each line into index and label\n",
    "    records = [line.split() for line in data]\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(records, columns=['index', 'label'])\n",
    "    \n",
    "    # Convert txt file name to csv\n",
    "    csv_file = txt_file.replace('.txt', '.csv')\n",
    "    \n",
    "    # Save as csv\n",
    "    df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_dir, output_dir):\n",
    "    \n",
    "    # Get all the .mp4 files in the directory\n",
    "    videos = glob.glob(os.path.join(video_dir, '*.mp4'))\n",
    "\n",
    "    # Make sure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over each video\n",
    "    for video_path in videos:\n",
    "        \n",
    "        # Get the video filename without the extension\n",
    "        video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "        \n",
    "        # Open the video file\n",
    "        video = cv2.VideoCapture(video_path)\n",
    "\n",
    "        # Initialize the frame count\n",
    "        count = 0\n",
    "\n",
    "        while True:\n",
    "            # Read the next frame\n",
    "            ret, frame = video.read()\n",
    "\n",
    "            # If the frame is not valid, break the loop\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Write the frame to a JPEG file\n",
    "            frame_name = f\"{video_name}_frame{count:04d}.jpg\"\n",
    "            cv2.imwrite(os.path.join(output_dir, frame_name), frame)\n",
    "\n",
    "            # Increment the frame count\n",
    "            count += 1\n",
    "\n",
    "        # Release the video file\n",
    "        video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_frames('../gesture/data/test', '../gesture/data/test_img')\n",
    "# extract_frames('../gesture/data/val', '../gesture/data/val_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### data preprocessing\n",
    "# Instantiate a pre-trained ResNet50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))  # remove the last layer\n",
    "model.eval()\n",
    "\n",
    "# Transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from an image\n",
    "def extract_features(image_path):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Apply the transformation and add an extra dimension\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    \n",
    "    # Ensure we get the features from the correct device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    image = image.to(device)\n",
    "    model.to(device)\n",
    "\n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    \n",
    "    return features.cpu().numpy()\n",
    "\n",
    "# Directory containing images\n",
    "image_dir = 'path_to_your_images'\n",
    "\n",
    "# Dataframe to hold features\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Loop through each image in the directory\n",
    "for image_path in glob.glob(os.path.join(image_dir, '*.jpg')):\n",
    "    # Extract features from the image\n",
    "    features = extract_features(image_path)\n",
    "    \n",
    "    # Flatten the features and add them to the dataframe\n",
    "    df = df.append(pd.Series(features.flatten()), ignore_index=True)\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/user/git/MiraeCity/gesture/data/test_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3636\\3272006702.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/user/git/MiraeCity/gesture/data/test_img'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#extract_features('../gesture/data/val_img')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3636\\1541967432.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Load the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Apply the transformation and add an extra dimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3235\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3236\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3237\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/user/git/MiraeCity/gesture/data/test_img'"
     ]
    }
   ],
   "source": [
    "extract_features('C:/Users/user/git/MiraeCity/gesture/data/test_img')\n",
    "#extract_features('../gesture/data/val_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_df = pd.read_csv('C:/Users/user/git/MiraeCity/gesture/labels/csv/train_ann.csv')\n",
    "# test_df = pd.read_csv('C:/Users/user/git/MiraeCity/gesture/labels/csv/test_ann.csv')\n",
    "\n",
    "train_data = TabularDataset(train_df)\n",
    "test_data = TabularDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4-10_001-C01.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4-10_001-C04.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4-10_001-C05.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4-10_001-C06.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-10_001-C07.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7555</th>\n",
       "      <td>13-5_601-C10.mp4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7556</th>\n",
       "      <td>13-5_601-C11.mp4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7557</th>\n",
       "      <td>13-5_601-C12.mp4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7558</th>\n",
       "      <td>13-5_602-C01.mp4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7559</th>\n",
       "      <td>13-5_602-C02.mp4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7560 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 index  label\n",
       "0     4-10_001-C01.mp4      0\n",
       "1     4-10_001-C04.mp4      0\n",
       "2     4-10_001-C05.mp4      0\n",
       "3     4-10_001-C06.mp4      0\n",
       "4     4-10_001-C07.mp4      0\n",
       "...                ...    ...\n",
       "7555  13-5_601-C10.mp4      4\n",
       "7556  13-5_601-C11.mp4      4\n",
       "7557  13-5_601-C12.mp4      4\n",
       "7558  13-5_602-C01.mp4      4\n",
       "7559  13-5_602-C02.mp4      4\n",
       "\n",
       "[7560 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### autogluon\n",
    "label = 'label'\n",
    "eval_metric = 'accuracy'\n",
    "time_limit = 3600 * 0.5 # hrs\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=label, eval_metric=eval_metric\n",
    ").fit(train_data, presets='best_quality', time_limit=time_limit, ag_args_fit={'num_gpus': 0, 'num_cpus': 12})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
