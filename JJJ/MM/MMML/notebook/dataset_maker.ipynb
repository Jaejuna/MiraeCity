{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sd_sn_file_match(directory_path, wav_file = '**/**.wav'):\n",
    "    file_list = glob(os.path.join(directory_path, wav_file), recursive=True)\n",
    "    \n",
    "    sd_files = []\n",
    "    sn_files = []\n",
    "\n",
    "    for i in range(len(file_list)):\n",
    "        sd_file_path = file_list[i]\n",
    "        dir_path, sd_file_name = os.path.split(sd_file_path)\n",
    "        sd_checker = re.sub('[^VN]', '', sd_file_name)\n",
    "\n",
    "        if sd_checker == 'VN':\n",
    "            sn_file_name = re.sub('VN', 'NV', sd_file_name)\n",
    "            sn_file_path = os.path.join(dir_path, sn_file_name)\n",
    "\n",
    "            if os.path.isfile(sd_file_path) == False:\n",
    "                continue\n",
    "            if os.path.isfile(sn_file_path) == False:\n",
    "                continue\n",
    "\n",
    "            sd_files.append(sd_file_path)\n",
    "            sn_files.append(sn_file_path)\n",
    "            \n",
    "    df = pd.DataFrame(zip(sd_files, sn_files), columns = ['sd_file_path', 'sn_file_path'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_to_key(path, sep='_', start=0, end=-1):\n",
    "    filename = os.path.basename(path)\n",
    "    filename, ext = os.path.splitext(filename)\n",
    "    key = filename.split(sep)[start:end]\n",
    "    key = sep.join(key)\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_match(directory_path, clean_name = '**/**_VN.wav', noisy_name='**/**_NV.wav', script_name='**/**_VN.json'):\n",
    "    \n",
    "    clean_list = glob(os.path.join(directory_path, clean_name), recursive=True)\n",
    "    noisy_list = glob(os.path.join(directory_path, noisy_name), recursive=True)\n",
    "    script_list = glob(os.path.join(directory_path, script_name), recursive=True)\n",
    "\n",
    "    df_clean_list = pd.DataFrame({'key':map(filename_to_key, clean_list), 'clean_path':clean_list})\n",
    "    df_noisy_list = pd.DataFrame({'key':map(filename_to_key, noisy_list), 'noisy_path':noisy_list})\n",
    "    df_script_list = pd.DataFrame({'key':map(filename_to_key, script_list), 'script_path':script_list})\n",
    "\n",
    "    df = pd.merge(df_clean_list, df_noisy_list, on=['key'])\n",
    "    df = pd.merge(df, df_script_list, on=['key'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_shuffle(df, train_ratio = 0.8, test_ratio = 0.1):\n",
    "    data_length = len(df)\n",
    "    indices = np.array(list(range(data_length)))\n",
    "\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_indices = indices[:int(data_length*train_ratio)]\n",
    "    valid_indices = indices[int(data_length*train_ratio):int(data_length*(1-test_ratio))]\n",
    "    test_indices = indices[int(data_length*(1-test_ratio)):]\n",
    "\n",
    "    df.loc[train_indices, 'train_val_test']='TR'\n",
    "    df.loc[valid_indices, 'train_val_test']='VA'\n",
    "    df.loc[test_indices, 'train_val_test']='TE'\n",
    "\n",
    "    #df = df.loc[indices].reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset_root DATASET_ROOT]\n",
      "                             [--csv_save_path CSV_SAVE_PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"5f4ff2d2-5376-45d6-93c7-b08ea87c1f02\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=c:\\Users\\user\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-1908842Dq3J8wqsIt.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\SpecTransformer\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    from dataloader.DataLoader import DataLoader\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='make csv')\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--dataset_root\",\n",
    "        default='share',\n",
    "        help=\"\"\" default : 'share' \"\"\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--csv_save_path\",\n",
    "        default='share/dataset.csv',\n",
    "        help=\"\"\" default : 'share/dataset.csv' \"\"\"\n",
    "    )\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    print('setting parameters')\n",
    "    if args.dataset_root:print('dataset_root : {}'.format(args.dataset_root))\n",
    "    if args.csv_save_path:print('csv_save_path : {}'.format(args.csv_save_path))\n",
    "    \n",
    "    df = file_match(args.dataset_root)\n",
    "    df = train_val_test_shuffle(df)\n",
    "    df.to_csv(args.csv_save_path, mode='w', header=True, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    tvt, counts = np.unique(df['train_val_test'], return_counts=True)\n",
    "    print(pd.DataFrame({\"train_val_test\":tvt, \"count\":counts}))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpecTransformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
