{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaejuna/MiraeCity/blob/JJJ/EDA_%EC%97%B0%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJO4S38uwWDE"
      },
      "source": [
        "# EDA 연습 - 퇴근후딴짓"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RynA3QXmwRP9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhzC5FT_wgxB"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvPXKYnJwoGf"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCm-k_rvgF5U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pViaJuKvgGBD"
      },
      "source": [
        "# 캐글 공유 코드 - 오디오 EDA\n",
        "\n",
        "https://www.kaggle.com/code/coldpumpkin/mfcc-feature-extraction-classification-and-eda\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "347IaVb1suzz"
      },
      "outputs": [],
      "source": [
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ripKaze5gI0B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import IPython\n",
        "import IPython.display as ipd\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1kqzEZTs36W"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv('../input/birdsong-recognition/train.csv')\n",
        "# df_train\n",
        "\n",
        "# dataset split 필요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Eq2ZDy9tAoG"
      },
      "outputs": [],
      "source": [
        "def mfcc_extract(filename):\n",
        "    try:\n",
        "        y, sr  = librosa.load(filename, sr = 44100)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, n_fft=int(0.02*sr),hop_length=int(0.01*sr))\n",
        "        return mfcc\n",
        "    except:\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EShQVnEMtEK7"
      },
      "outputs": [],
      "source": [
        "def parse_audio_files(parent_dir, sub_dirs, limit):\n",
        "    labels = []\n",
        "    features = []\n",
        "    for label, sub_dir in enumerate(tqdm(sub_dirs)):\n",
        "        i = 0\n",
        "        for fn in glob.glob(os.path.join(parent_dir,sub_dir,\"*.mp3\")):\n",
        "            if i >= limit:\n",
        "                break\n",
        "            features.append(mfcc_extract(fn))\n",
        "            labels.append(label)\n",
        "            i+=1\n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFXoDKLCtIxX"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "train_cat_dirs = glob.glob(train_dir+'/*')\n",
        "train_cat = []\n",
        "for cat_dir in train_cat_dirs:\n",
        "    tmp = cat_dir.split('/')[-1]\n",
        "    train_cat.append(tmp)\n",
        "print('the number of kinds:', len(train_cat))\n",
        "\n",
        "class_num = len(train_cat)\n",
        "features, labels = parse_audio_files(train_dir, train_cat, LIMIT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwgECLestJWC"
      },
      "outputs": [],
      "source": [
        "print(len(features))\n",
        "print(features[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89gWocDstOo1"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(28,24))\n",
        "for i,mfcc in enumerate(tqdm(features[:100])):\n",
        "    if i%40 < 3 :\n",
        "        sub = plt.subplot(10,3,i%40+3*(i/40)+1)\n",
        "        librosa.display.specshow(mfcc,vmin=-700,vmax=300)\n",
        "        if ((i%40+3*(i/40)+1)%3==0) :\n",
        "            plt.colorbar()\n",
        "        sub.set_title(train_cat[labels[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEpzUe6Vt0bf"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure(data=[\n",
        "    go.Bar(y=species.values, x=species.index,marker_color='deeppink')\n",
        "])\n",
        "\n",
        "fig.update_layout(title='type 분포')\n",
        "fig.show()\n",
        "\n",
        "## 위 처럼 피처 종류 별로 분포를 그래프로 시각화해서 데이터에 대한 분석 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt1vWwNEt1pN"
      },
      "outputs": [],
      "source": [
        "# sampling rate analysis\n",
        "rec = train.sampling_rate.value_counts()\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(x=rec.index, y=rec.values,marker_color='deeppink')\n",
        "])\n",
        "\n",
        "fig.update_layout(title='Top Recordists')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqIEKjxlusGH"
      },
      "outputs": [],
      "source": [
        "# channel (mono, stereo; 아마 없을 )\n",
        "rec = train.channels.value_counts()\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(x=rec.index, y=rec.values,marker_color='deeppink')\n",
        "])\n",
        "\n",
        "fig.update_layout(title='Top Recordists')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYm06ITGu2QI"
      },
      "outputs": [],
      "source": [
        "# audio signal length\n",
        "df=train.length.value_counts()\n",
        "fig = px.pie(df,df.index,df.values,labels={'index':'length of audio'})\n",
        "fig.update_layout(title='Length of audio signal')\n",
        "fig.update_traces(hoverinfo='label+percent', textinfo='value', textfont_size=20,\n",
        "                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOxsCinRvN_J"
      },
      "outputs": [],
      "source": [
        "## 지리적 분석 (해당 코드는 미국을 집약적으로 분석한 것, 이것도 아마 없을 듯)\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scattergeo( #그래프의 종류와 데이터 옵션을 지정\n",
        "        locationmode = 'USA-states', #위치의 항목을 지도의 영역과 일치시키는 데 사용되는 위치 집합을 결정\n",
        "        lon = df['longitude'],\n",
        "        lat = df['latitude'],\n",
        "        text = df['ebird_code'],\n",
        "        marker = dict(\n",
        "            size = df['ebird_code'],\n",
        "            line_color='rgb(40,40,40)',\n",
        "            line_width=0.5,\n",
        "            sizemode = 'area'\n",
        "        )))\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "        title_text = 'Bird Samples collected From USA',\n",
        "        showlegend = True,\n",
        "        geo = dict(\n",
        "            scope = 'usa',\n",
        "            landcolor = 'rgb(217, 217, 217)',\n",
        "        )\n",
        "    )\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGDh4aMwvv0v"
      },
      "source": [
        "--------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61aBABhfvycK"
      },
      "outputs": [],
      "source": [
        "# playing audio\n",
        "# path=\"../input/birdsong-recognition/train_audio/\"\n",
        "birds=train.ebird_code.unique()[:6]\n",
        "file=train[train.ebird_code==birds[0]]['filename'][0]\n",
        "\n",
        "for i in range(0,2):\n",
        "    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n",
        "    audio_path=os.path.join(path,birds[i],file)\n",
        "    print(birds[i])\n",
        "    IPython.display.display(ipd.Audio(audio_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANq7NloHwEM5"
      },
      "outputs": [],
      "source": [
        "# waveform visualization\n",
        "plt.figure(figsize=(17,20 ))\n",
        "\n",
        "\n",
        "for i in range(0,6):\n",
        "    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n",
        "    audio_path=os.path.join(path,birds[i],file)\n",
        "    plt.subplot(6,2,i+1)\n",
        "    x , sr = librosa.load(audio_path) #오디오 파일을 읽어 샘플을 리스트로 반환해줌\n",
        "    librosa.display.waveplot(x, sr=sr,color='r')\n",
        "    plt.gca().set_title(birds[i])\n",
        "    plt.gca().get_xaxis().set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_gKBT-OwPoa"
      },
      "outputs": [],
      "source": [
        "# spectrogram\n",
        "plt.figure(figsize=(17,20 ))\n",
        "\n",
        "\n",
        "for i in range(0,6):\n",
        "    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n",
        "    audio_path=os.path.join(path,birds[i],file)\n",
        "    plt.subplot(6,2,i+1)\n",
        "    x , sr = librosa.load(audio_path)\n",
        "    x = librosa.stft(x) # 데이터의 스펙트로그램을 리턴\n",
        "    Xdb = librosa.amplitude_to_db(abs(x)) # 스펙트로그램을 dB 스케일\n",
        "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
        "    plt.gca().set_title(birds[i])\n",
        "    plt.gca().get_xaxis().set_visible(False)\n",
        "    plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cJI2A5jxClU"
      },
      "outputs": [],
      "source": [
        "# mel-spectrogram\n",
        "### n_fft = 2048\n",
        "win_length = 2048\n",
        "hop_length = 1024\n",
        "n_mels = 128\n",
        "\n",
        "plt.figure(figsize=(17,20 ))\n",
        "\n",
        "\n",
        "for i in range(0,6):\n",
        "    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n",
        "    audio_path=os.path.join(path,birds[i],file)\n",
        "    plt.subplot(6,2,i+1)\n",
        "    x , sr = librosa.load(audio_path)\n",
        "    x = librosa.stft(x) # 데이터의 스펙트로그램을 리턴\n",
        "    mel_spec = librosa.feature.melspectrogram(S=x, sr=sr, n_mels=n_mels, hop_length=hop_length, win_length=win_length)\n",
        "    Xdb = librosa.amplitude_to_db(abs(mel_spec)) # 스펙트로그램을 dB 스케일\n",
        "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
        "    plt.gca().set_title(birds[i])\n",
        "    plt.gca().get_xaxis().set_visible(False)\n",
        "    plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLMDFkeBxP4u"
      },
      "source": [
        "## feature extraction\n",
        "\n",
        "여기서부터는 푸리에 변환을 통해 time domain 에서 frequency domain으로 데이터를 바꾸어 특징을 추출하는 기술\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueIlTajnxvot"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "# 시각화를 위해서 스펙트럼 중심을 정규화 하는 함수\n",
        "def normalize(x, axis=0):\n",
        "    return sklearn.preprocessing.minmax_scale(x, axis=axis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYIJgyFzxzYs"
      },
      "outputs": [],
      "source": [
        "#### Spectral centroid\n",
        "plt.figure(figsize=(17,20 ))\n",
        "\n",
        "for i in range(0,6):\n",
        "    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n",
        "    audio_path=os.path.join(path,birds[i],file)\n",
        "    plt.subplot(6,2,i+1)\n",
        "    x , sr = librosa.load(audio_path)\n",
        "    spectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]\n",
        "    frames = range(len(spectral_centroids))\n",
        "    t = librosa.frames_to_time(frames)\n",
        "    librosa.display.waveplot(x, sr=sr, alpha=0.4)\n",
        "    plt.plot(t, normalize(spectral_centroids), color='b')\n",
        "    plt.gca().set_title(birds[i])\n",
        "    plt.gca().get_xaxis().set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### zero crossing rate\n",
        "x , sr = librosa.load(audio_path)\n",
        "plt.figure(figsize=(14, 5))\n",
        "librosa.display.waveplot(x, sr=sr)\n",
        "# Zooming in\n",
        "n0 = 9000\n",
        "n1 = 9100\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(x[n0:n1])\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "V76bWVQukKQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_crossings = librosa.zero_crossings(x[n0:n1], pad=False)\n",
        "print(sum(zero_crossings))"
      ],
      "metadata": {
        "id": "rSmkJlC2lbFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### MFCC\n",
        "plt.figure(figsize=(17, 20))\n",
        "\n",
        "for i in range(0,6):\n",
        "    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n",
        "    audio_path=os.path.join(path,birds[i],file)\n",
        "    plt.subplot(6,2,i+1)\n",
        "    x , sr = librosa.load(audio_path)\n",
        "    mfccs = librosa.feature.mfcc(x, sr=sr)\n",
        "    librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
        "    plt.gca().set_title(birds[i])\n",
        "    plt.gca().get_xaxis().set_visible(False)"
      ],
      "metadata": {
        "id": "_j3quYytlemk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Chroma feature\n",
        "plt.figure(figsize=(17, 20))\n",
        "\n",
        "for i in range(0,6):\n",
        "    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n",
        "    audio_path=os.path.join(path,birds[i],file)\n",
        "    plt.subplot(6,3,i+1)\n",
        "    x , sr = librosa.load(audio_path)\n",
        "    chromagram = librosa.feature.chroma_stft(x, sr=sr)\n",
        "    librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma')\n",
        "    plt.gca().set_title(birds[i])\n",
        "    plt.gca().get_xaxis().set_visible(False)"
      ],
      "metadata": {
        "id": "eX7W0R4blllM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(15,15))\n",
        "k=1\n",
        "for i in range(5):\n",
        "\n",
        "    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n",
        "    audio_path=os.path.join(path,birds[i],file)\n",
        "    plt.subplot(5,3,k)\n",
        "    k+=1\n",
        "    x , sr = librosa.load(audio_path)\n",
        "    s = librosa.stft(x)\n",
        "    Xdb = librosa.amplitude_to_db(abs(s))\n",
        "        librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
        "    plt.gca().set_title('Spectrogram')\n",
        "    plt.gca().set_ylabel(birds[i])\n",
        "    plt.gca().get_xaxis().set_visible(False)\n",
        "\n",
        "    plt.subplot(5,3,k)\n",
        "    k+=1\n",
        "    mfccs = librosa.feature.mfcc(x, sr=sr)\n",
        "    librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
        "    plt.gca().set_title('MFFC features ')\n",
        "    plt.gca().get_xaxis().set_visible(False)\n",
        "        plt.subplot(5,3,k)\n",
        "    k+=1\n",
        "    chromagram = librosa.feature.chroma_stft(x, sr=sr)\n",
        "    librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', cmap='coolwarm')\n",
        "    plt.gca().set_title('Chroma feature')\n",
        "    plt.gca().get_xaxis().set_visible(False)\n",
        "\n",
        "#fig.suptitle('Comparing audio features for bird species')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vGncSn0wlqd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t3Xx5UHgJY0"
      },
      "source": [
        "# 캐글 공유 코드 - 이미지 EDA\n",
        "https://www.kaggle.com/code/dariussingh/nfl-multipose-estimation-using-yolov8-mediapipe 는 참고만\n",
        "<br/>\n",
        "especially pose estimation EDA\n",
        "\n",
        "chatGPT로 EDA 구현\n",
        "\n",
        "**possible features**:\n",
        "Raw keypoints, Relative distances, agngles, temporal changes, Velocity, acceleration, joint relationships, symmetry, historical data, pose embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load an image\n",
        "img = cv2.imread('path_to_your_image.jpg')\n",
        "\n",
        "# Convert from BGR to RGB\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aCY1hWdkl_0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'labels' is a list of your labels\n",
        "import pandas as pd\n",
        "\n",
        "# Convert to a pandas Series for easier frequency calculation\n",
        "labels_series = pd.Series(labels)\n",
        "\n",
        "# Show the distribution of labels\n",
        "print(labels_series.value_counts())"
      ],
      "metadata": {
        "id": "xIHOheKbsnC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'keypoints' is a list of your keypoints\n",
        "keypoints_series = pd.Series(keypoints)\n",
        "\n",
        "# Show the distribution of keypoints\n",
        "print(keypoints_series.describe())"
      ],
      "metadata": {
        "id": "4xWQwmmUs7GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Define a transform\n",
        "transform = transforms.RandomHorizontalFlip()\n",
        "\n",
        "# Apply the transform to the image\n",
        "transformed_img = transform(img)\n",
        "\n",
        "# Display the original and transformed images\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(img)\n",
        "ax[1].imshow(transformed_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CTaz6JIhtAgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------\n",
        "will perform feature extraction and EDA"
      ],
      "metadata": {
        "id": "QX9AqMlpu0WM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XxCEdnUeu2l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5oXLPjIgQzZ"
      },
      "source": [
        "# 캐글 공유 코드 - 멀티모달 EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8i6qShlgQ9h"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsE3ACqzAntfK85FyFpAY/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}