{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import librosa\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import json\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### hyperparameter\n",
    "CFG = {\n",
    "    'SR':16000,\n",
    "    'N_MFCC':128, # Melspectrogram 벡터를 추출할 개수\n",
    "    'SEED':42\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### fixed random seed\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(CFG['SEED']) # seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### data preprocessing\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_filelist(subfolder, file_extension):\n",
    "    data_path = Path.cwd()/subfolder\n",
    "    \n",
    "    return list(data_path.glob('**/*' + file_extension))\n",
    "\n",
    "root_path = 'C:/Users/user/git/MiraeCity/SR/data/1.Training/label/07.터미널/'\n",
    "\n",
    "# 이 파일이 위치해있는 폴더의 하위폴더 'data'에 있는 확장자명이 '.json'인 모든 파일을 불러옵니다\n",
    "files = get_filelist(root_path+ '*' ,'json')\n",
    "\n",
    "# 저장할 데이터 항목의 이름을 입력합니다. json 파일에 적힌 항목(key)과 같아야합니다.\n",
    "column_names = ['dataSet', 'version', 'mediaUrl', 'date', 'typeInfo', 'conversationType', 'speakerNumber', 'speakers', 'dialogs', 'samplingRate', 'recStime', 'recLen', 'recDevice']\n",
    "result = pd.DataFrame(columns=column_names)   \n",
    "\n",
    "for json_file in files:\n",
    "    df = pd.read_json(json_file)\n",
    "    row_data = pd.json_normalize(data=df['row'])\n",
    "    print(row_data.head(2)) #데이터가 잘 불러와지는지 확인하는 출력\n",
    "    \n",
    "    result = pd.concat([result,df])\n",
    "    \n",
    "# 현재 이 파일이 위치한 폴더의 하위 폴더 data 에 'result.csv'로 저장\n",
    "result.to_csv(Path.cwd()/'data'/'01.기차역대합실.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataSet', 'version', 'mediaUrl', 'date', 'typeInfo', 'conversationType', 'speakerNumber', 'speakers', 'dialogs', 'samplingRate', 'recStime', 'recLen', 'recDevice']\n"
     ]
    }
   ],
   "source": [
    "datas = json.load(open('C:/Users/user/git/MiraeCity/SR/data/1.Training/label/06.지하철,버스/01.지하철플랫폼/06_01_000817_210811_SD.json', 'r'))\n",
    "\n",
    "keys = [key for key in datas]\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### json to csv\n",
    "rootdir = 'C:/Users/user/git/MiraeCity/SR/data/01.데이터/1.Training/label/TL/07.터미널/01.기차역대합실'  # Enter your directory here\n",
    "\n",
    "file_list = [f for f in os.scandir(rootdir) if f.is_file() and f.name.endswith('.json')]\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file in file_list:\n",
    "    with open(file, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "        \n",
    "        # Flatten 'typeInfo', 'speakers' and 'dialogs' separately\n",
    "        typeInfo_df = json_normalize(json_data, record_path='typeInfo', meta=['dataSet', 'version', 'mediaUrl', 'date', 'conversationType', 'speakerNumber'], errors='ignore')\n",
    "        speakers_df = json_normalize(json_data, record_path='speakers', meta=['dataSet', 'version', 'mediaUrl', 'date', 'conversationType', 'speakerNumber'], errors='ignore')\n",
    "        dialogs_df = json_normalize(json_data, record_path='dialogs', meta=['dataSet', 'version', 'mediaUrl', 'date', 'conversationType', 'speakerNumber'], errors='ignore')\n",
    "        \n",
    "        # Concatenate all data into one DataFrame\n",
    "        dataframes.append(pd.concat([typeInfo_df, speakers_df, dialogs_df], axis=1))\n",
    "\n",
    "# Concatenate all data from different JSON files\n",
    "big_frame = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "big_frame.to_csv('01.기차역대합실.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### csv concat\n",
    "####### train, valid csv todo\n",
    "\n",
    "# list all csv files in the directory\n",
    "csv_dir = 'C:/Users/user/git/MiraeCity/SR/data/2.Validation/label/csv/'\n",
    "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
    "\n",
    "# read and concatenate all csv files\n",
    "df_list = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(os.path.join(csv_dir, csv_file))\n",
    "    df_list.append(df)\n",
    "\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# write concatenated dataframe to a new csv file\n",
    "final_df.to_csv('concatenated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### data preprocessing\n",
    "train_df = pd.read_csv('C:/Users/user/git/MiraeCity/SR/data/01.데이터/1.Training/label/01.기차역대합실.csv')\n",
    "test_df = pd.read_csv('C:/Users/user/git/MiraeCity/SR/data/01.데이터/2.Validation/label/01.기차역대합실.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('C:/Users/user/git/MiraeCity/SR/data/01.데이터/1.Training/label/01.기차역대합실.csv', nrows=10)\n",
    "print(sample_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### zip 파일 압축 해제\n",
    "import zipfile\n",
    "\n",
    "def unzip_file(zip_filepath, dest_path):\n",
    "    with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dest_path)\n",
    "\n",
    "zip_filepath = 'C:/Users/user/git/MiraeCity/SR/data/1.Training/raw/TS2_06.지하철,버스_02.지하철안.zip'  # replace with your zip file path\n",
    "dest_path = 'C:/Users/user/git/MiraeCity/SR/data/1.Training/raw'  # replace with the path where you want to extract files\n",
    "\n",
    "unzip_file(zip_filepath, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### mfcc feature extract function\n",
    "rootdir = 'C:/Users/user/git/MiraeCity/SR/data/01.데이터/2.Validation/raw/VS_07.터미널/'\n",
    "\n",
    "def get_mfcc_feature(df):\n",
    "    features = []\n",
    "    for path in tqdm(df['mediaUrl'].astype(str)):\n",
    "        full_path = os.path.join(rootdir, path)\n",
    "        try:\n",
    "            y, sr = librosa.load(full_path, sr=CFG['SR'])\n",
    "        except FileNotFoundError:\n",
    "            #print(f\"File {full_path} not found.\")\n",
    "            continue\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CFG['N_MFCC'])\n",
    "        features.append({\n",
    "            'mfcc_mean': np.mean(mfcc, axis=1),\n",
    "            'mfcc_max': np.max(mfcc, axis=1),\n",
    "            'mfcc_min': np.min(mfcc, axis=1),\n",
    "        })\n",
    "    if not features:  # If features list is empty\n",
    "        print(\"No valid audio files found.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame\n",
    "    else:\n",
    "        print(\"Found features\")\n",
    "\n",
    "    mfcc_df = pd.DataFrame(features)\n",
    "    mfcc_mean_df = pd.DataFrame(mfcc_df['mfcc_mean'].tolist(), columns=[f'mfcc_mean_{i}' for i in range(CFG['N_MFCC'])])\n",
    "    mfcc_max_df = pd.DataFrame(mfcc_df['mfcc_max'].tolist(), columns=[f'mfcc_max_{i}' for i in range(CFG['N_MFCC'])])\n",
    "    mfcc_min_df = pd.DataFrame(mfcc_df['mfcc_min'].tolist(), columns=[f'mfcc_min_{i}' for i in range(CFG['N_MFCC'])])\n",
    "\n",
    "    return pd.concat([mfcc_mean_df, mfcc_max_df, mfcc_min_df], axis=1)\n",
    "\n",
    "##### mel feature extract function\n",
    "def get_feature_mel(df):\n",
    "    features = []\n",
    "    for path in tqdm(df['mediaUrl'].astype(str)):\n",
    "        full_path = os.path.join(rootdir, path)\n",
    "        try:\n",
    "            y, sr = librosa.load(full_path, sr=CFG['SR'])\n",
    "        except FileNotFoundError:\n",
    "            #print(f\"File {full_path} not found.\")\n",
    "            continue\n",
    "        n_fft = 2048\n",
    "        win_length = 2048\n",
    "        hop_length = 1024\n",
    "        n_mels = 128\n",
    "\n",
    "        D = np.abs(librosa.stft(y, n_fft=n_fft, win_length = win_length, hop_length=hop_length))\n",
    "        mel = librosa.feature.melspectrogram(S=D, sr=sr, n_mels=n_mels, hop_length=hop_length, win_length=win_length)\n",
    "\n",
    "        features.append({\n",
    "            'mel_mean': mel.mean(axis=1),\n",
    "            'mel_max': mel.min(axis=1),\n",
    "            'mel_min': mel.max(axis=1),\n",
    "        })\n",
    "        \n",
    "    if not features:  # If features list is empty\n",
    "        print(\"No valid audio files found.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame\n",
    "    else:\n",
    "        print(\"Found features\")\n",
    "\n",
    "    mel_df = pd.DataFrame(features)\n",
    "    mel_mean_df = pd.DataFrame(mel_df['mel_mean'].tolist(), columns=[f'mel_mean_{i}' for i in range(n_mels)])\n",
    "    mel_max_df = pd.DataFrame(mel_df['mel_max'].tolist(), columns=[f'mel_max_{i}' for i in range(n_mels)])\n",
    "    mel_min_df = pd.DataFrame(mel_df['mel_min'].tolist(), columns=[f'mel_min_{i}' for i in range(n_mels)])\n",
    "\n",
    "    return pd.concat([mel_mean_df, mel_max_df, mel_min_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51e739cfed8439492ea1657c59b21d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19740\\2823901898.py:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(full_path, sr=CFG['SR'])\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid audio files found.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28548e28f9174412994309ddb80d597e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4575 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19740\\2823901898.py:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(full_path, sr=CFG['SR'])\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d326c39bc675432096dbf7f52669c4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19740\\2823901898.py:38: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(full_path, sr=CFG['SR'])\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid audio files found.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b83bda4d5c145138beb8ea275797165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4575 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found features\n"
     ]
    }
   ],
   "source": [
    "train_mf = get_mfcc_feature(train_df)\n",
    "test_mf = get_mfcc_feature(test_df)\n",
    "\n",
    "train_mel = get_feature_mel(train_df)\n",
    "test_mel = get_feature_mel(test_df)\n",
    "\n",
    "train_x = pd.concat([train_mel, train_mf], axis=1)\n",
    "test_x = pd.concat([test_mel, test_mf], axis=1)\n",
    "\n",
    "train_y = train_df['place']\n",
    "\n",
    "#train_x['place'] = train_df['place']\n",
    "#test_x['place'] = test_df['place']\n",
    "\n",
    "train_x['place'] = train_df['place'].fillna(method='ffill')\n",
    "test_x['place'] = test_df['place'].fillna(method='ffill')\n",
    "\n",
    "# train_x.dropna(subset=['place'], inplace=True)\n",
    "# test_x.dropna(subset=['place'], inplace=True)\n",
    "\n",
    "train_data = TabularDataset(train_x)\n",
    "test_data = TabularDataset(test_x)\n",
    "\n",
    "# train_data = pd.concat([train_data, test_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mel_mean_0  mel_mean_1  mel_mean_2  mel_mean_3  mel_mean_4  mel_mean_5  \\\n",
      "0      0.194321    0.362591    0.433129    0.264966    0.189134    0.352695   \n",
      "1      0.213185    0.368740    0.416187    0.303982    0.319825    0.424623   \n",
      "2      0.345119    0.476485    0.514477    0.342951    0.334910    0.389481   \n",
      "3      0.046725    0.093747    0.111278    0.101546    0.106966    0.156729   \n",
      "4      0.051330    0.097078    0.118053    0.122123    0.118884    0.135077   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "258    0.045257    0.145505    0.201457    0.141556    0.143485    0.231502   \n",
      "259    0.051619    0.182746    0.300776    0.603530    0.278957    0.187884   \n",
      "260    0.047302    0.143825    0.171655    0.123403    0.133860    0.129655   \n",
      "261    0.079806    0.158248    0.200954    0.216048    0.189978    0.218465   \n",
      "262    0.073091    0.131891    0.161752    0.141749    0.165858    0.210938   \n",
      "\n",
      "     mel_mean_6  mel_mean_7  mel_mean_8  mel_mean_9  ...  mfcc_min_119  \\\n",
      "0      0.736115    0.458742    0.529991    0.585614  ...     -5.913292   \n",
      "1      0.359131    0.408996    0.484159    0.432182  ...     -6.148245   \n",
      "2      0.373237    0.504337    0.626411    0.503408  ...     -6.808262   \n",
      "3      0.149002    0.187185    0.194283    0.191557  ...     -7.017041   \n",
      "4      0.123429    0.241437    0.414584    0.430205  ...     -8.698196   \n",
      "..          ...         ...         ...         ...  ...           ...   \n",
      "258    0.189710    0.285733    0.366593    0.391082  ...     -5.385108   \n",
      "259    0.248564    0.423297    0.449916    0.444895  ...     -8.173893   \n",
      "260    0.283965    0.469452    0.418735    0.445598  ...     -5.237949   \n",
      "261    0.325714    0.469699    0.484471    0.604696  ...     -5.932480   \n",
      "262    0.255259    0.331323    0.352578    0.481754  ...     -5.640157   \n",
      "\n",
      "     mfcc_min_120  mfcc_min_121  mfcc_min_122  mfcc_min_123  mfcc_min_124  \\\n",
      "0       -7.164398     -7.511324     -7.105166     -7.594909     -6.389519   \n",
      "1       -8.274553     -6.963616     -6.603176     -8.527864     -8.425905   \n",
      "2       -7.483726     -6.706218     -6.763474     -6.373231     -6.837139   \n",
      "3       -6.395185     -5.461801     -6.037868     -8.190642     -5.463415   \n",
      "4       -6.452520     -6.224705     -5.869876     -5.791517     -6.583370   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "258     -6.349785     -5.595156     -5.712327     -5.278345     -5.869947   \n",
      "259     -6.802484     -6.967816     -6.653421     -7.029779     -6.416094   \n",
      "260     -5.679618     -5.239775     -5.777370     -5.964725     -6.539685   \n",
      "261     -5.427059     -5.679393     -6.144232     -5.856544     -6.271361   \n",
      "262     -6.994925     -6.256290     -5.447013     -5.868959     -5.733110   \n",
      "\n",
      "     mfcc_min_125  mfcc_min_126  mfcc_min_127         place  \n",
      "0       -6.349087     -7.689433     -6.421894  KTX서울역 바로위지상  \n",
      "1       -7.460810     -9.811363     -8.198822  KTX서울역 바로위지상  \n",
      "2       -6.624315     -5.853630     -6.093937  KTX서울역 바로위지상  \n",
      "3       -7.278533     -6.264816     -6.417538  KTX서울역 바로위지상  \n",
      "4       -6.234658     -6.607359     -5.558495  KTX서울역 바로위지상  \n",
      "..            ...           ...           ...           ...  \n",
      "258     -6.279552     -5.561485     -5.139198           부산역  \n",
      "259     -6.404888     -7.161153     -6.564812           부산역  \n",
      "260     -8.012948     -7.096410     -5.176502           부산역  \n",
      "261     -6.110330     -6.171915     -5.020626           부산역  \n",
      "262     -5.608925     -5.831000     -5.528526           부산역  \n",
      "\n",
      "[263 rows x 769 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)\n",
    "test_data.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230604_024034\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=5, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230604_024034\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Train Data Rows:    263\n",
      "Train Data Columns: 768\n",
      "Label Column: place\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t4 unique label values:  ['KTX서울역 바로위지상', '서울역 KTX 지하대기실', '서울역KTX 지하대기실', '부산역']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19796.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 768 | ['mel_mean_0', 'mel_mean_1', 'mel_mean_2', 'mel_mean_3', 'mel_mean_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 768 | ['mel_mean_0', 'mel_mean_1', 'mel_mean_2', 'mel_mean_3', 'mel_mean_4', ...]\n",
      "\t0.4s = Fit runtime\n",
      "\t768 features in original data used to generate 768 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.81 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.42s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3599.58s of the 3599.57s of remaining time.\n",
      "\t0.6084\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3598.8s of the 3598.8s of remaining time.\n",
      "\t0.616\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3598.7s of the 3598.7s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6806\t = Validation score   (accuracy)\n",
      "\t22.71s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3569.25s of the 3569.24s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6616\t = Validation score   (accuracy)\n",
      "\t16.77s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3549.83s of the 3549.82s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.616\t = Validation score   (accuracy)\n",
      "\t17.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3530.25s of the 3530.25s of remaining time.\n",
      "\t0.5703\t = Validation score   (accuracy)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 3529.63s of the 3529.63s of remaining time.\n",
      "\t0.5779\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3528.94s of the 3528.94s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6046\t = Validation score   (accuracy)\n",
      "\t252.18s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 3274.24s of the 3274.24s of remaining time.\n",
      "\t0.5779\t = Validation score   (accuracy)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3273.69s of the 3273.69s of remaining time.\n",
      "\t0.5589\t = Validation score   (accuracy)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3273.11s of the 3273.11s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.597\t = Validation score   (accuracy)\n",
      "\t33.5s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3237.0s of the 3237.0s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6464\t = Validation score   (accuracy)\n",
      "\t16.79s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3217.48s of the 3217.48s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5589\t = Validation score   (accuracy)\n",
      "\t31.82s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3183.12s of the 3183.12s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6768\t = Validation score   (accuracy)\n",
      "\t44.12s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3159.29s of the 3159.29s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6122\t = Validation score   (accuracy)\n",
      "\t32.41s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3141.14s of the 3141.14s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6122\t = Validation score   (accuracy)\n",
      "\t32.77s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3122.94s of the 3122.94s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5856\t = Validation score   (accuracy)\n",
      "\t479.78s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2892.93s of the 2892.92s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5665\t = Validation score   (accuracy)\n",
      "\t64.6s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2859.33s of the 2859.32s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6198\t = Validation score   (accuracy)\n",
      "\t33.42s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2840.11s of the 2840.11s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5627\t = Validation score   (accuracy)\n",
      "\t64.76s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Repeating k-fold bagging: 3/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2804.58s of the 2804.58s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6806\t = Validation score   (accuracy)\n",
      "\t66.98s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2779.24s of the 2779.23s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6046\t = Validation score   (accuracy)\n",
      "\t48.7s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2760.34s of the 2760.34s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.597\t = Validation score   (accuracy)\n",
      "\t49.72s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2740.86s of the 2740.85s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6046\t = Validation score   (accuracy)\n",
      "\t688.53s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2529.54s of the 2529.54s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5817\t = Validation score   (accuracy)\n",
      "\t95.03s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2496.63s of the 2496.62s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6274\t = Validation score   (accuracy)\n",
      "\t50.48s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2476.97s of the 2476.97s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5589\t = Validation score   (accuracy)\n",
      "\t97.19s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Repeating k-fold bagging: 4/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2442.05s of the 2442.04s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6882\t = Validation score   (accuracy)\n",
      "\t88.84s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2417.63s of the 2417.62s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6236\t = Validation score   (accuracy)\n",
      "\t64.78s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2398.95s of the 2398.95s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.597\t = Validation score   (accuracy)\n",
      "\t66.36s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2379.8s of the 2379.79s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5932\t = Validation score   (accuracy)\n",
      "\t939.69s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2126.16s of the 2126.16s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5779\t = Validation score   (accuracy)\n",
      "\t125.4s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2093.31s of the 2093.3s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6274\t = Validation score   (accuracy)\n",
      "\t67.13s\t = Training   runtime\n",
      "\t1.53s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2074.1s of the 2074.09s of remaining time.\n",
      "\tFitting 5 child models (S4F1 - S4F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5779\t = Validation score   (accuracy)\n",
      "\t130.17s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Repeating k-fold bagging: 5/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2038.59s of the 2038.58s of remaining time.\n",
      "\tFitting 5 child models (S5F1 - S5F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6958\t = Validation score   (accuracy)\n",
      "\t111.14s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2013.75s of the 2013.75s of remaining time.\n",
      "\tFitting 5 child models (S5F1 - S5F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6084\t = Validation score   (accuracy)\n",
      "\t81.02s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1994.94s of the 1994.93s of remaining time.\n",
      "\tFitting 5 child models (S5F1 - S5F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5894\t = Validation score   (accuracy)\n",
      "\t83.38s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1975.46s of the 1975.45s of remaining time.\n",
      "\tFitting 5 child models (S5F1 - S5F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5932\t = Validation score   (accuracy)\n",
      "\t1195.85s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1716.83s of the 1716.83s of remaining time.\n",
      "\tFitting 5 child models (S5F1 - S5F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.597\t = Validation score   (accuracy)\n",
      "\t159.56s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1680.19s of the 1680.18s of remaining time.\n",
      "\tFitting 5 child models (S5F1 - S5F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.635\t = Validation score   (accuracy)\n",
      "\t83.96s\t = Training   runtime\n",
      "\t1.9s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1660.79s of the 1660.79s of remaining time.\n",
      "\tFitting 5 child models (S5F1 - S5F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5779\t = Validation score   (accuracy)\n",
      "\t163.24s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Repeating k-fold bagging: 6/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1625.2s of the 1625.19s of remaining time.\n",
      "\tFitting 5 child models (S6F1 - S6F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6882\t = Validation score   (accuracy)\n",
      "\t134.06s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1599.78s of the 1599.77s of remaining time.\n",
      "\tFitting 5 child models (S6F1 - S6F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6122\t = Validation score   (accuracy)\n",
      "\t97.07s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1581.12s of the 1581.12s of remaining time.\n",
      "\tFitting 5 child models (S6F1 - S6F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6046\t = Validation score   (accuracy)\n",
      "\t100.29s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1561.73s of the 1561.72s of remaining time.\n",
      "\tFitting 5 child models (S6F1 - S6F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5932\t = Validation score   (accuracy)\n",
      "\t1456.93s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1298.15s of the 1298.15s of remaining time.\n",
      "\tFitting 5 child models (S6F1 - S6F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5894\t = Validation score   (accuracy)\n",
      "\t190.93s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1264.25s of the 1264.25s of remaining time.\n",
      "\tFitting 5 child models (S6F1 - S6F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6274\t = Validation score   (accuracy)\n",
      "\t100.81s\t = Training   runtime\n",
      "\t2.27s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1244.86s of the 1244.85s of remaining time.\n",
      "\tFitting 5 child models (S6F1 - S6F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5932\t = Validation score   (accuracy)\n",
      "\t195.82s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Repeating k-fold bagging: 7/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1209.77s of the 1209.76s of remaining time.\n",
      "\tFitting 5 child models (S7F1 - S7F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6882\t = Validation score   (accuracy)\n",
      "\t156.37s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1184.96s of the 1184.96s of remaining time.\n",
      "\tFitting 5 child models (S7F1 - S7F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.616\t = Validation score   (accuracy)\n",
      "\t113.44s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1165.96s of the 1165.96s of remaining time.\n",
      "\tFitting 5 child models (S7F1 - S7F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6008\t = Validation score   (accuracy)\n",
      "\t117.06s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1146.72s of the 1146.71s of remaining time.\n",
      "\tFitting 5 child models (S7F1 - S7F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5932\t = Validation score   (accuracy)\n",
      "\t1729.2s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 871.98s of the 871.97s of remaining time.\n",
      "\tFitting 5 child models (S7F1 - S7F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6084\t = Validation score   (accuracy)\n",
      "\t223.72s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 836.69s of the 836.69s of remaining time.\n",
      "\tFitting 5 child models (S7F1 - S7F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6274\t = Validation score   (accuracy)\n",
      "\t117.85s\t = Training   runtime\n",
      "\t2.65s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 817.13s of the 817.13s of remaining time.\n",
      "\tFitting 5 child models (S7F1 - S7F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5894\t = Validation score   (accuracy)\n",
      "\t228.81s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Repeating k-fold bagging: 8/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 781.64s of the 781.63s of remaining time.\n",
      "\tFitting 5 child models (S8F1 - S8F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6806\t = Validation score   (accuracy)\n",
      "\t178.79s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 756.68s of the 756.67s of remaining time.\n",
      "\tFitting 5 child models (S8F1 - S8F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6122\t = Validation score   (accuracy)\n",
      "\t130.25s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 737.32s of the 737.32s of remaining time.\n",
      "\tFitting 5 child models (S8F1 - S8F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6084\t = Validation score   (accuracy)\n",
      "\t133.78s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 718.0s of the 718.0s of remaining time.\n",
      "\tFitting 5 child models (S8F1 - S8F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.597\t = Validation score   (accuracy)\n",
      "\t1937.1s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 507.6s of the 507.59s of remaining time.\n",
      "\tFitting 5 child models (S8F1 - S8F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6008\t = Validation score   (accuracy)\n",
      "\t255.05s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 473.76s of the 473.75s of remaining time.\n",
      "\tFitting 5 child models (S8F1 - S8F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6274\t = Validation score   (accuracy)\n",
      "\t134.68s\t = Training   runtime\n",
      "\t3.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 454.34s of the 454.34s of remaining time.\n",
      "\tFitting 5 child models (S8F1 - S8F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6122\t = Validation score   (accuracy)\n",
      "\t261.79s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Completed 8/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 418.79s of remaining time.\n",
      "\t0.7034\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3181.38s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230604_024034\\\")\n"
     ]
    }
   ],
   "source": [
    "#### autogluon\n",
    "label = 'place'\n",
    "eval_metric = 'accuracy'\n",
    "time_limit = 3600 * 1 # hrs\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=label, eval_metric=eval_metric\n",
    ").fit(test_data, presets='best_quality', time_limit=time_limit, ag_args_fit={'num_gpus': 0, 'num_cpus': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.913978</td>\n",
       "      <td>1.083753</td>\n",
       "      <td>709.569122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147008</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.897849</td>\n",
       "      <td>0.309414</td>\n",
       "      <td>276.264465</td>\n",
       "      <td>0.309414</td>\n",
       "      <td>276.264465</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.897849</td>\n",
       "      <td>0.774339</td>\n",
       "      <td>433.157649</td>\n",
       "      <td>0.774339</td>\n",
       "      <td>433.157649</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.881720</td>\n",
       "      <td>0.289712</td>\n",
       "      <td>273.603543</td>\n",
       "      <td>0.289712</td>\n",
       "      <td>273.603543</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>6.946900</td>\n",
       "      <td>334.759939</td>\n",
       "      <td>6.946900</td>\n",
       "      <td>334.759939</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.291355</td>\n",
       "      <td>274.315669</td>\n",
       "      <td>0.291355</td>\n",
       "      <td>274.315669</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.743648</td>\n",
       "      <td>978.384512</td>\n",
       "      <td>0.743648</td>\n",
       "      <td>978.384512</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.865591</td>\n",
       "      <td>0.051349</td>\n",
       "      <td>0.356773</td>\n",
       "      <td>0.051349</td>\n",
       "      <td>0.356773</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.865591</td>\n",
       "      <td>0.292059</td>\n",
       "      <td>309.976674</td>\n",
       "      <td>0.292059</td>\n",
       "      <td>309.976674</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.049998</td>\n",
       "      <td>0.348104</td>\n",
       "      <td>0.049998</td>\n",
       "      <td>0.348104</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.051310</td>\n",
       "      <td>0.360866</td>\n",
       "      <td>0.051310</td>\n",
       "      <td>0.360866</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>0.422271</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>0.422271</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.051651</td>\n",
       "      <td>0.388518</td>\n",
       "      <td>0.051651</td>\n",
       "      <td>0.388518</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_val  pred_time_val    fit_time  \\\n",
       "0       WeightedEnsemble_L2   0.913978       1.083753  709.569122   \n",
       "1            XGBoost_BAG_L1   0.897849       0.309414  276.264465   \n",
       "2    NeuralNetFastAI_BAG_L1   0.897849       0.774339  433.157649   \n",
       "3         LightGBMXT_BAG_L1   0.881720       0.289712  273.603543   \n",
       "4     NeuralNetTorch_BAG_L1   0.876344       6.946900  334.759939   \n",
       "5           LightGBM_BAG_L1   0.870968       0.291355  274.315669   \n",
       "6           CatBoost_BAG_L1   0.870968       0.743648  978.384512   \n",
       "7     ExtraTreesGini_BAG_L1   0.865591       0.051349    0.356773   \n",
       "8      LightGBMLarge_BAG_L1   0.865591       0.292059  309.976674   \n",
       "9     ExtraTreesEntr_BAG_L1   0.854839       0.049998    0.348104   \n",
       "10  RandomForestEntr_BAG_L1   0.854839       0.051310    0.360866   \n",
       "11    KNeighborsDist_BAG_L1   0.844086       0.001001    0.031000   \n",
       "12    KNeighborsUnif_BAG_L1   0.844086       0.006001    0.422271   \n",
       "13  RandomForestGini_BAG_L1   0.827957       0.051651    0.388518   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000000           0.147008            2       True   \n",
       "1                 0.309414         276.264465            1       True   \n",
       "2                 0.774339         433.157649            1       True   \n",
       "3                 0.289712         273.603543            1       True   \n",
       "4                 6.946900         334.759939            1       True   \n",
       "5                 0.291355         274.315669            1       True   \n",
       "6                 0.743648         978.384512            1       True   \n",
       "7                 0.051349           0.356773            1       True   \n",
       "8                 0.292059         309.976674            1       True   \n",
       "9                 0.049998           0.348104            1       True   \n",
       "10                0.051310           0.360866            1       True   \n",
       "11                0.001001           0.031000            1       True   \n",
       "12                0.006001           0.422271            1       True   \n",
       "13                0.051651           0.388518            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          14  \n",
       "1          11  \n",
       "2          10  \n",
       "3           3  \n",
       "4          12  \n",
       "5           4  \n",
       "6           7  \n",
       "7           8  \n",
       "8          13  \n",
       "9           9  \n",
       "10          6  \n",
       "11          2  \n",
       "12          1  \n",
       "13          5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### leaderboard\n",
    "predictor.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### inference \n",
    "model_to_use = predictor.get_model_best()\n",
    "model_pred = predictor.predict(test_data, model=model_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### result\n",
    "result = pd.DataFrame()\n",
    "\n",
    "result['place'] = model_pred\n",
    "result.to_csv('result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
